{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "756560cd-1c64-4ba4-bb1c-a9d5ce097054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Evaluation with Mosaic AI Agent Evaluation\n",
    "\n",
    "In this lab, you will have the opportunity to evaluate a RAG chain model **using Mosaic AI Agent Evaluation Framework.**\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "*In this lab, you will complete the following tasks:*\n",
    "\n",
    "- **Task 1**: Define a custom Gen AI evaluation metric.\n",
    "\n",
    "- **Task 2**: Conduct an evaluation test using the Agent Evaluation Framework.\n",
    "\n",
    "- **Task 3**: Analyze the evaluation results through the user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33ff1997-de99-4b52-84f2-59d671a4b234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qq databricks-agents databricks-sdk databricks-vectorsearch langchain-databricks langchain==0.3.7 mlflow tiktoken langchain-community==0.3.7\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e83837c2-04b6-427b-b035-be40089a3a43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nThe examples and models presented in this course are intended solely for demonstration and educational purposes.\n Please note that the models and prompt examples may sometimes contain offensive, inaccurate, biased, or harmful content.\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865b5b81-48a3-492b-8f1e-ce5b142073e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username:          labuser11003544_1753435669@vocareum.com\nCatalog Name:      dbacademy\nSchema Name:       labuser11003544_1753435669\nWorking Directory: /Volumes/dbacademy/ops/labuser11003544_1753435669@vocareum_com\nDataset Location:  NestedNamespace (news='/Volumes/dbacademy_news/v01', arxiv='/Volumes/dbacademy_arxiv/v01')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5441a98-5f30-43d4-9812-4cb37bd80540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Lab Overview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b388c91b-2813-4e3c-84c8-4e6392bf7f22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation Dataset\n",
    "\n",
    "In this lab, you will work with the same dataset utilized in the demos. This dataset contains sample queries along with their corresponding expected responses, which are generated using synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce56da61-24dd-4995-a383-f885e1735920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>request</th><th>expected_response</th><th>evolution_type</th><th>episode_done</th></tr></thead><tbody><tr><td>What are the limitations of symbolic planning in task and motion planning, and how can leveraging large language models help overcome these limitations?</td><td>Symbolic planning in task and motion planning can be limited by the need for explicit primitives and constraints. Leveraging large language models can help overcome these limitations by enabling the robot to use language models for planning and execution, and by providing a way to extract and leverage knowledge from large language models to solve temporally extended tasks.</td><td>simple</td><td>true</td></tr><tr><td>What are some techniques used to fine-tune transformer models for personalized code generation, and how effective are they in improving prediction accuracy and preventing runtime errors? </td><td>The techniques used to fine-tune transformer models for personalized code generation include ﬁne-tuning transformer models, adopting a novel approach called Target Similarity Tuning (TST) to retrieve a small set of examples from a training bank, and utilizing these examples to train a pretrained language model. The effectiveness of these techniques is shown in the improvement in prediction accuracy and the prevention of runtime errors.</td><td>simple</td><td>true</td></tr><tr><td>How does the PPO-ptx model mitigate performance regressions in the few-shot setting?</td><td>The PPO-ptx model mitigates performance regressions in the few-shot setting by incorporating pre-training and fine-tuning on the downstream task. This approach allows the model to learn generalizable features and adapt to new tasks more effectively, leading to improved few-shot performance.</td><td>simple</td><td>true</td></tr><tr><td>How can complex questions be decomposed using successive prompting?</td><td>Successive prompting is a method for decomposing complex questions into simpler sub-questions, allowing language models to answer them more accurately. This approach was proposed by Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner in their paper 'Successive Prompting for Decomposing Complex Questions', presented at EMNLP 2022.</td><td>simple</td><td>true</td></tr><tr><td>Which entity type in Named Entity Recognition is likely to be involved in information extraction, question answering, semantic parsing, and machine translation?</td><td>Organization</td><td>reasoning</td><td>true</td></tr><tr><td>What is the purpose of ROUGE (Recall-Oriented Understudy for Gisting Evaluation) in automatic evaluation methods?</td><td>ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is used in automatic evaluation methods to evaluate the quality of machine translation. It calculates N-gram co-occurrence statistics, which are used to assess the similarity between the candidate text and the reference text. ROUGE is based on recall, whereas BLEU is based on accuracy.</td><td>simple</td><td>true</td></tr><tr><td>What are the challenges associated with Foundation SSL in CV, and how do they relate to the lack of theoretical foundation, semantic understanding, and explicable exploration?</td><td>The challenges associated with Foundation SSL in CV include the lack of a profound theory to support all kinds of tentative experiments, and further exploration has no handbook. The pretrained LM may not learn the meaning of the language, relying on corpus learning instead. The models cannot reach a better level of stability and match different downstream tasks, and the primary method is to increase data, improve computation power, and design training procedures to achieve better results. The lack of theoretical foundation, semantic understanding, and explicable exploration are the main challenges in Foundation SSL in CV.</td><td>simple</td><td>true</td></tr><tr><td>How does ChatGPT handle factual input compared to GPT-3.5?</td><td>ChatGPT handles factual input better than GPT-3.5, with a 21.9% increase in accuracy when the premise entails the hypothesis. This is possibly related to the preference for human feedback in ChatGPT's RLHF design during model training.</td><td>simple</td><td>true</td></tr><tr><td>What are some of the challenges in understanding natural language commands for robotic navigation and mobile manipulation?</td><td>Some challenges in understanding natural language commands for robotic navigation and mobile manipulation include integrating natural language understanding with reinforcement learning, understanding natural language directions for robotic navigation, and mapping instructions and visual observations to actions with reinforcement learning.</td><td>simple</td><td>true</td></tr><tr><td>How does chain of thought prompting elicit reasoning in large language models, and what are the potential applications of this technique in neural text generation and human-AI interaction?</td><td>The context discusses the use of chain of thought prompting to elicit reasoning in large language models, which can be applied in neural text generation and human-AI interaction. Specifically, researchers have used this technique to train language models to generate coherent and contextually relevant text, and to create transparent and controllable human-AI interaction systems. The potential applications of this technique include improving the performance of language models in generating contextually appropriate responses, enhancing the interpretability and controllability of AI systems, and facilitating more effective human-AI collaboration.</td><td>simple</td><td>true</td></tr><tr><td>Using the given context, how can the robot be instructed to move objects around on a tabletop to complete rearrangement tasks?</td><td>The robot can be instructed to move objects around on a tabletop to complete rearrangement tasks by using natural language instructions that specify the objects to be moved and their desired locations. The instructions can be parsed using functions such as parse_obj_name and parse_position to extract the necessary information, and then passed to a motion primitive that can pick up and place objects in the specified locations. The get_obj_names and get_obj_pos APIs can be used to access information about the available objects and their locations in the scene.</td><td>reasoning</td><td>true</td></tr><tr><td>How can searching over an organization's existing knowledge, data, or documents using LLM-powered applications reduce the time it takes to complete worker activities?</td><td>Using AI tools to search through a company's information can significantly cut down the time workers need to finish tasks. These tools quickly find and provide the necessary details by scanning large amounts of data efficiently.</td><td>simple</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What are the limitations of symbolic planning in task and motion planning, and how can leveraging large language models help overcome these limitations?",
         "Symbolic planning in task and motion planning can be limited by the need for explicit primitives and constraints. Leveraging large language models can help overcome these limitations by enabling the robot to use language models for planning and execution, and by providing a way to extract and leverage knowledge from large language models to solve temporally extended tasks.",
         "simple",
         true
        ],
        [
         "What are some techniques used to fine-tune transformer models for personalized code generation, and how effective are they in improving prediction accuracy and preventing runtime errors? ",
         "The techniques used to fine-tune transformer models for personalized code generation include ﬁne-tuning transformer models, adopting a novel approach called Target Similarity Tuning (TST) to retrieve a small set of examples from a training bank, and utilizing these examples to train a pretrained language model. The effectiveness of these techniques is shown in the improvement in prediction accuracy and the prevention of runtime errors.",
         "simple",
         true
        ],
        [
         "How does the PPO-ptx model mitigate performance regressions in the few-shot setting?",
         "The PPO-ptx model mitigates performance regressions in the few-shot setting by incorporating pre-training and fine-tuning on the downstream task. This approach allows the model to learn generalizable features and adapt to new tasks more effectively, leading to improved few-shot performance.",
         "simple",
         true
        ],
        [
         "How can complex questions be decomposed using successive prompting?",
         "Successive prompting is a method for decomposing complex questions into simpler sub-questions, allowing language models to answer them more accurately. This approach was proposed by Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner in their paper 'Successive Prompting for Decomposing Complex Questions', presented at EMNLP 2022.",
         "simple",
         true
        ],
        [
         "Which entity type in Named Entity Recognition is likely to be involved in information extraction, question answering, semantic parsing, and machine translation?",
         "Organization",
         "reasoning",
         true
        ],
        [
         "What is the purpose of ROUGE (Recall-Oriented Understudy for Gisting Evaluation) in automatic evaluation methods?",
         "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is used in automatic evaluation methods to evaluate the quality of machine translation. It calculates N-gram co-occurrence statistics, which are used to assess the similarity between the candidate text and the reference text. ROUGE is based on recall, whereas BLEU is based on accuracy.",
         "simple",
         true
        ],
        [
         "What are the challenges associated with Foundation SSL in CV, and how do they relate to the lack of theoretical foundation, semantic understanding, and explicable exploration?",
         "The challenges associated with Foundation SSL in CV include the lack of a profound theory to support all kinds of tentative experiments, and further exploration has no handbook. The pretrained LM may not learn the meaning of the language, relying on corpus learning instead. The models cannot reach a better level of stability and match different downstream tasks, and the primary method is to increase data, improve computation power, and design training procedures to achieve better results. The lack of theoretical foundation, semantic understanding, and explicable exploration are the main challenges in Foundation SSL in CV.",
         "simple",
         true
        ],
        [
         "How does ChatGPT handle factual input compared to GPT-3.5?",
         "ChatGPT handles factual input better than GPT-3.5, with a 21.9% increase in accuracy when the premise entails the hypothesis. This is possibly related to the preference for human feedback in ChatGPT's RLHF design during model training.",
         "simple",
         true
        ],
        [
         "What are some of the challenges in understanding natural language commands for robotic navigation and mobile manipulation?",
         "Some challenges in understanding natural language commands for robotic navigation and mobile manipulation include integrating natural language understanding with reinforcement learning, understanding natural language directions for robotic navigation, and mapping instructions and visual observations to actions with reinforcement learning.",
         "simple",
         true
        ],
        [
         "How does chain of thought prompting elicit reasoning in large language models, and what are the potential applications of this technique in neural text generation and human-AI interaction?",
         "The context discusses the use of chain of thought prompting to elicit reasoning in large language models, which can be applied in neural text generation and human-AI interaction. Specifically, researchers have used this technique to train language models to generate coherent and contextually relevant text, and to create transparent and controllable human-AI interaction systems. The potential applications of this technique include improving the performance of language models in generating contextually appropriate responses, enhancing the interpretability and controllability of AI systems, and facilitating more effective human-AI collaboration.",
         "simple",
         true
        ],
        [
         "Using the given context, how can the robot be instructed to move objects around on a tabletop to complete rearrangement tasks?",
         "The robot can be instructed to move objects around on a tabletop to complete rearrangement tasks by using natural language instructions that specify the objects to be moved and their desired locations. The instructions can be parsed using functions such as parse_obj_name and parse_position to extract the necessary information, and then passed to a motion primitive that can pick up and place objects in the specified locations. The get_obj_names and get_obj_pos APIs can be used to access information about the available objects and their locations in the scene.",
         "reasoning",
         true
        ],
        [
         "How can searching over an organization's existing knowledge, data, or documents using LLM-powered applications reduce the time it takes to complete worker activities?",
         "Using AI tools to search through a company's information can significantly cut down the time workers need to finish tasks. These tools quickly find and provide the necessary details by scanning large amounts of data efficiently.",
         "simple",
         true
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "request",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "expected_response",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "evolution_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "episode_done",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(DA.eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc694938-2821-4430-9397-c507ab890036",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the Model\n",
    "\n",
    "A RAG chain has been created and registered for use in this lab. The model details are provided below.\n",
    "\n",
    "**\uD83D\uDCCC Note:** If you are using your own workspace to run this lab, you must manually execute **`00 - Build Model / 00-Build Model`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d0d7a15-e853-4d0c-aed8-3341b21ff14a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "catalog_name = \"genai_shared_catalog_03\"\n",
    "# schema_name = f\"ws_{spark.conf.get('spark.databricks.clusterUsageTags.clusterOwnerOrgId')}\"\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# model_uri = f\"models:/{catalog_name}.{schema_name}.rag_app/1\"\n",
    "model_name = \"genai_shared_catalog_03.ws_1286554779316081.rag_app\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd24ca10-2e8b-40cf-aa46-6462a10f906d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1 - Define A Custom Metric\n",
    "\n",
    "For this task, define a custom metric to evaluate whether the generated **\"ANSWER\"** from the RAG chain is easily readable by a non-expert user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b51a87fb-f097-4057-a3f1-0ee498296819",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.metrics.genai import make_genai_metric_from_prompt\n",
    "\n",
    "## Prompt for LLM as judge to determine if the generated response is easily readable by non-academic or expert readers\n",
    "eval_prompt = \"Your task is to determine whether the generated response easily readable by non-academic or expert readers. This was the content: '{retrieved_context}'\"\n",
    "\n",
    "## Use Llama-3 as LLM\n",
    "llm=\"endpoints:/databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "## Define the metric\n",
    "is_readable = make_genai_metric_from_prompt(\n",
    "    name=\"is_readable\",\n",
    "    judge_prompt=eval_prompt,\n",
    "    model=llm,\n",
    "    metric_metadata={\"assessment_type\": \"ANSWER\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2315a905-6d51-401f-b931-028ef96755b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 2 - Run Evaluation Test\n",
    "\n",
    "Next, run an evaluation using the custom metric you defined. Ensure that you select **Mosaic AI Agent Evaluation** as the evaluation type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ad99676-94c4-4db1-bc9a-49776171c70e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1b3951919145b08cae9ae60532abfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 11:32:38 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.11.11`, differs from the version of Python that is currently running, `Python 3.10.12`, and may be incompatible\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3791189952706433>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m model_uri \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:/genai_shared_catalog_03.ws_1286554779316081.rag_app/1\u001B[39m\u001B[38;5;124m\"\u001B[39m \n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlab_04_agent_evaluation\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[0;32m----> 3\u001B[0m     eval_results \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mevaluate(\n",
       "\u001B[1;32m      4\u001B[0m         data \u001B[38;5;241m=\u001B[39m DA\u001B[38;5;241m.\u001B[39meval_df,\n",
       "\u001B[1;32m      5\u001B[0m         model \u001B[38;5;241m=\u001B[39m model_uri,\n",
       "\u001B[1;32m      6\u001B[0m         model_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks-agent\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      7\u001B[0m         extra_metrics\u001B[38;5;241m=\u001B[39m[is_readable]\n",
       "\u001B[1;32m      8\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/models/evaluation/base.py:1685\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(model, data, model_type, targets, predictions, dataset_path, feature_names, evaluators, evaluator_config, custom_metrics, extra_metrics, custom_artifacts, validation_thresholds, baseline_model, env_manager, model_config, baseline_config, inference_params)\u001B[0m\n",
       "\u001B[1;32m   1683\u001B[0m         model \u001B[38;5;241m=\u001B[39m _get_model_from_deployment_endpoint_uri(model, inference_params)\n",
       "\u001B[1;32m   1684\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m-> 1685\u001B[0m         model \u001B[38;5;241m=\u001B[39m \u001B[43m_load_model_or_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1686\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m env_manager \u001B[38;5;241m!=\u001B[39m _EnvManager\u001B[38;5;241m.\u001B[39mLOCAL:\n",
       "\u001B[1;32m   1687\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n",
       "\u001B[1;32m   1688\u001B[0m         message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe model argument must be a string URI referring to an MLflow model when a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1689\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-local env_manager is specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   1690\u001B[0m         error_code\u001B[38;5;241m=\u001B[39mINVALID_PARAMETER_VALUE,\n",
       "\u001B[1;32m   1691\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1240\u001B[0m, in \u001B[0;36m_load_model_or_server\u001B[0;34m(model_uri, env_manager, model_config)\u001B[0m\n",
       "\u001B[1;32m   1234\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmlflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyfunc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscoring_server\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n",
       "\u001B[1;32m   1235\u001B[0m     ScoringServerClient,\n",
       "\u001B[1;32m   1236\u001B[0m     StdinScoringServerClient,\n",
       "\u001B[1;32m   1237\u001B[0m )\n",
       "\u001B[1;32m   1239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m env_manager \u001B[38;5;241m==\u001B[39m _EnvManager\u001B[38;5;241m.\u001B[39mLOCAL:\n",
       "\u001B[0;32m-> 1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1242\u001B[0m _logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting model server for model environment restoration.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m   1244\u001B[0m local_path \u001B[38;5;241m=\u001B[39m _download_artifact_from_uri(artifact_uri\u001B[38;5;241m=\u001B[39mmodel_uri)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/tracing/provider.py:422\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    420\u001B[0m disable()\n",
       "\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 422\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m    424\u001B[0m     enable()\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1133\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001B[0m\n",
       "\u001B[1;32m   1131\u001B[0m         model_impl \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(conf[MAIN])\u001B[38;5;241m.\u001B[39m_load_pyfunc(data_path, model_config)\n",
       "\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m-> 1133\u001B[0m         model_impl \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mMAIN\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_pyfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1134\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m   1135\u001B[0m     \u001B[38;5;66;03m# This error message is particularly for the case when the error is caused by module\u001B[39;00m\n",
       "\u001B[1;32m   1136\u001B[0m     \u001B[38;5;66;03m# \"databricks.feature_store.mlflow_model\". But depending on the environment, the offending\u001B[39;00m\n",
       "\u001B[1;32m   1137\u001B[0m     \u001B[38;5;66;03m# module might be \"databricks\", \"databricks.feature_store\" or full package. So we will\u001B[39;00m\n",
       "\u001B[1;32m   1138\u001B[0m     \u001B[38;5;66;03m# raise the error with the following note if \"databricks\" presents in the error. All non-\u001B[39;00m\n",
       "\u001B[1;32m   1139\u001B[0m     \u001B[38;5;66;03m# databricks module errors will just be re-raised.\u001B[39;00m\n",
       "\u001B[1;32m   1140\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m conf[MAIN] \u001B[38;5;241m==\u001B[39m _DATABRICKS_FS_LOADER_MODULE \u001B[38;5;129;01mand\u001B[39;00m e\u001B[38;5;241m.\u001B[39mname\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/__init__.py:844\u001B[0m, in \u001B[0;36m_load_pyfunc\u001B[0;34m(path, model_config)\u001B[0m\n",
       "\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_pyfunc\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m, model_config: Optional[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# noqa: D417\u001B[39;00m\n",
       "\u001B[1;32m    839\u001B[0m     \u001B[38;5;124;03m\"\"\"Load PyFunc implementation for LangChain. Called by ``pyfunc.load_model``.\u001B[39;00m\n",
       "\u001B[1;32m    840\u001B[0m \n",
       "\u001B[1;32m    841\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n",
       "\u001B[1;32m    842\u001B[0m \u001B[38;5;124;03m        path: Local filesystem path to the MLflow Model with the ``langchain`` flavor.\u001B[39;00m\n",
       "\u001B[1;32m    843\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 844\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _LangChainModelWrapper(\u001B[43m_load_model_from_local_fs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m, path)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/__init__.py:883\u001B[0m, in \u001B[0;36m_load_model_from_local_fs\u001B[0;34m(local_model_path, model_config_overrides)\u001B[0m\n",
       "\u001B[1;32m    881\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
       "\u001B[1;32m    882\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 883\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_model_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflavor_conf\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/utils/__init__.py:584\u001B[0m, in \u001B[0;36mpatch_langchain_type_to_cls_dict.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    581\u001B[0m     module\u001B[38;5;241m.\u001B[39mget_type_to_cls_dict \u001B[38;5;241m=\u001B[39m _patched_get_type_to_cls_dict(originals[name])\n",
       "\u001B[1;32m    583\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 584\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    586\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m m \u001B[38;5;241m:=\u001B[39m _CHAT_MODELS_ERROR_MSG\u001B[38;5;241m.\u001B[39msearch(\u001B[38;5;28mstr\u001B[39m(e)):\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/__init__.py:631\u001B[0m, in \u001B[0;36m_load_model\u001B[0;34m(local_model_path, flavor_conf)\u001B[0m\n",
       "\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m register_pydantic_v1_serializer_cm():\n",
       "\u001B[1;32m    630\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _RUNNABLE_LOAD_KEY:\n",
       "\u001B[0;32m--> 631\u001B[0m         model \u001B[38;5;241m=\u001B[39m \u001B[43m_load_runnables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_model_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflavor_conf\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    632\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _BASE_LOAD_KEY:\n",
       "\u001B[1;32m    633\u001B[0m         model \u001B[38;5;241m=\u001B[39m _load_base_lcs(local_model_path, flavor_conf)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:505\u001B[0m, in \u001B[0;36m_load_runnables\u001B[0;34m(path, conf)\u001B[0m\n",
       "\u001B[1;32m    503\u001B[0m model_data \u001B[38;5;241m=\u001B[39m conf\u001B[38;5;241m.\u001B[39mget(_MODEL_DATA_KEY, _MODEL_DATA_YAML_FILE_NAME)\n",
       "\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lc_runnable_with_steps_types()):\n",
       "\u001B[0;32m--> 505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnable_with_steps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n",
       "\u001B[1;32m    507\u001B[0m     model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m picklable_runnable_types())\n",
       "\u001B[1;32m    508\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m model_data \u001B[38;5;241m==\u001B[39m _MODEL_DATA_PKL_FILE_NAME\n",
       "\u001B[1;32m    509\u001B[0m ):\n",
       "\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_from_pickle(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data))\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:140\u001B[0m, in \u001B[0;36m_load_runnable_with_steps\u001B[0;34m(file_path, model_type)\u001B[0m\n",
       "\u001B[1;32m    138\u001B[0m     config \u001B[38;5;241m=\u001B[39m steps_conf\u001B[38;5;241m.\u001B[39mget(step)\n",
       "\u001B[1;32m    139\u001B[0m     \u001B[38;5;66;03m# load model from the folder of the step\u001B[39;00m\n",
       "\u001B[0;32m--> 140\u001B[0m     runnable \u001B[38;5;241m=\u001B[39m \u001B[43m_load_model_from_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    141\u001B[0m     steps[step] \u001B[38;5;241m=\u001B[39m runnable\n",
       "\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;241m==\u001B[39m RunnableSequence\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:96\u001B[0m, in \u001B[0;36m_load_model_from_path\u001B[0;34m(path, model_config)\u001B[0m\n",
       "\u001B[1;32m     94\u001B[0m model_load_fn \u001B[38;5;241m=\u001B[39m model_config\u001B[38;5;241m.\u001B[39mget(_MODEL_LOAD_KEY)\n",
       "\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _RUNNABLE_LOAD_KEY:\n",
       "\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _BASE_LOAD_KEY:\n",
       "\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_base_lcs(path, model_config)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:505\u001B[0m, in \u001B[0;36m_load_runnables\u001B[0;34m(path, conf)\u001B[0m\n",
       "\u001B[1;32m    503\u001B[0m model_data \u001B[38;5;241m=\u001B[39m conf\u001B[38;5;241m.\u001B[39mget(_MODEL_DATA_KEY, _MODEL_DATA_YAML_FILE_NAME)\n",
       "\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lc_runnable_with_steps_types()):\n",
       "\u001B[0;32m--> 505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnable_with_steps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n",
       "\u001B[1;32m    507\u001B[0m     model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m picklable_runnable_types())\n",
       "\u001B[1;32m    508\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m model_data \u001B[38;5;241m==\u001B[39m _MODEL_DATA_PKL_FILE_NAME\n",
       "\u001B[1;32m    509\u001B[0m ):\n",
       "\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_from_pickle(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data))\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:140\u001B[0m, in \u001B[0;36m_load_runnable_with_steps\u001B[0;34m(file_path, model_type)\u001B[0m\n",
       "\u001B[1;32m    138\u001B[0m     config \u001B[38;5;241m=\u001B[39m steps_conf\u001B[38;5;241m.\u001B[39mget(step)\n",
       "\u001B[1;32m    139\u001B[0m     \u001B[38;5;66;03m# load model from the folder of the step\u001B[39;00m\n",
       "\u001B[0;32m--> 140\u001B[0m     runnable \u001B[38;5;241m=\u001B[39m \u001B[43m_load_model_from_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    141\u001B[0m     steps[step] \u001B[38;5;241m=\u001B[39m runnable\n",
       "\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;241m==\u001B[39m RunnableSequence\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:96\u001B[0m, in \u001B[0;36m_load_model_from_path\u001B[0;34m(path, model_config)\u001B[0m\n",
       "\u001B[1;32m     94\u001B[0m model_load_fn \u001B[38;5;241m=\u001B[39m model_config\u001B[38;5;241m.\u001B[39mget(_MODEL_LOAD_KEY)\n",
       "\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _RUNNABLE_LOAD_KEY:\n",
       "\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _BASE_LOAD_KEY:\n",
       "\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_base_lcs(path, model_config)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:505\u001B[0m, in \u001B[0;36m_load_runnables\u001B[0;34m(path, conf)\u001B[0m\n",
       "\u001B[1;32m    503\u001B[0m model_data \u001B[38;5;241m=\u001B[39m conf\u001B[38;5;241m.\u001B[39mget(_MODEL_DATA_KEY, _MODEL_DATA_YAML_FILE_NAME)\n",
       "\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lc_runnable_with_steps_types()):\n",
       "\u001B[0;32m--> 505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnable_with_steps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n",
       "\u001B[1;32m    507\u001B[0m     model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m picklable_runnable_types())\n",
       "\u001B[1;32m    508\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m model_data \u001B[38;5;241m==\u001B[39m _MODEL_DATA_PKL_FILE_NAME\n",
       "\u001B[1;32m    509\u001B[0m ):\n",
       "\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_from_pickle(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data))\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:140\u001B[0m, in \u001B[0;36m_load_runnable_with_steps\u001B[0;34m(file_path, model_type)\u001B[0m\n",
       "\u001B[1;32m    138\u001B[0m     config \u001B[38;5;241m=\u001B[39m steps_conf\u001B[38;5;241m.\u001B[39mget(step)\n",
       "\u001B[1;32m    139\u001B[0m     \u001B[38;5;66;03m# load model from the folder of the step\u001B[39;00m\n",
       "\u001B[0;32m--> 140\u001B[0m     runnable \u001B[38;5;241m=\u001B[39m \u001B[43m_load_model_from_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    141\u001B[0m     steps[step] \u001B[38;5;241m=\u001B[39m runnable\n",
       "\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;241m==\u001B[39m RunnableSequence\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:96\u001B[0m, in \u001B[0;36m_load_model_from_path\u001B[0;34m(path, model_config)\u001B[0m\n",
       "\u001B[1;32m     94\u001B[0m model_load_fn \u001B[38;5;241m=\u001B[39m model_config\u001B[38;5;241m.\u001B[39mget(_MODEL_LOAD_KEY)\n",
       "\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _RUNNABLE_LOAD_KEY:\n",
       "\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _BASE_LOAD_KEY:\n",
       "\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_base_lcs(path, model_config)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:510\u001B[0m, in \u001B[0;36m_load_runnables\u001B[0;34m(path, conf)\u001B[0m\n",
       "\u001B[1;32m    505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_runnable_with_steps(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data), model_type)\n",
       "\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n",
       "\u001B[1;32m    507\u001B[0m     model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m picklable_runnable_types())\n",
       "\u001B[1;32m    508\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m model_data \u001B[38;5;241m==\u001B[39m _MODEL_DATA_PKL_FILE_NAME\n",
       "\u001B[1;32m    509\u001B[0m ):\n",
       "\u001B[0;32m--> 510\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_from_pickle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lc_runnable_branch_types()):\n",
       "\u001B[1;32m    512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_runnable_branch(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data))\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/utils/__init__.py:421\u001B[0m, in \u001B[0;36m_load_from_pickle\u001B[0;34m(path)\u001B[0m\n",
       "\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_from_pickle\u001B[39m(path):\n",
       "\u001B[1;32m    420\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
       "\u001B[0;32m--> 421\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcloudpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: code expected at most 16 arguments, got 18"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "code expected at most 16 arguments, got 18"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: code expected at most 16 arguments, got 18"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-3791189952706433>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model_uri \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:/genai_shared_catalog_03.ws_1286554779316081.rag_app/1\u001B[39m\u001B[38;5;124m\"\u001B[39m \n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlab_04_agent_evaluation\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m----> 3\u001B[0m     eval_results \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mevaluate(\n\u001B[1;32m      4\u001B[0m         data \u001B[38;5;241m=\u001B[39m DA\u001B[38;5;241m.\u001B[39meval_df,\n\u001B[1;32m      5\u001B[0m         model \u001B[38;5;241m=\u001B[39m model_uri,\n\u001B[1;32m      6\u001B[0m         model_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks-agent\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m         extra_metrics\u001B[38;5;241m=\u001B[39m[is_readable]\n\u001B[1;32m      8\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/models/evaluation/base.py:1685\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(model, data, model_type, targets, predictions, dataset_path, feature_names, evaluators, evaluator_config, custom_metrics, extra_metrics, custom_artifacts, validation_thresholds, baseline_model, env_manager, model_config, baseline_config, inference_params)\u001B[0m\n\u001B[1;32m   1683\u001B[0m         model \u001B[38;5;241m=\u001B[39m _get_model_from_deployment_endpoint_uri(model, inference_params)\n\u001B[1;32m   1684\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1685\u001B[0m         model \u001B[38;5;241m=\u001B[39m \u001B[43m_load_model_or_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1686\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m env_manager \u001B[38;5;241m!=\u001B[39m _EnvManager\u001B[38;5;241m.\u001B[39mLOCAL:\n\u001B[1;32m   1687\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m   1688\u001B[0m         message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe model argument must be a string URI referring to an MLflow model when a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1689\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-local env_manager is specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1690\u001B[0m         error_code\u001B[38;5;241m=\u001B[39mINVALID_PARAMETER_VALUE,\n\u001B[1;32m   1691\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1240\u001B[0m, in \u001B[0;36m_load_model_or_server\u001B[0;34m(model_uri, env_manager, model_config)\u001B[0m\n\u001B[1;32m   1234\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmlflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyfunc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscoring_server\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m   1235\u001B[0m     ScoringServerClient,\n\u001B[1;32m   1236\u001B[0m     StdinScoringServerClient,\n\u001B[1;32m   1237\u001B[0m )\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m env_manager \u001B[38;5;241m==\u001B[39m _EnvManager\u001B[38;5;241m.\u001B[39mLOCAL:\n\u001B[0;32m-> 1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1242\u001B[0m _logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting model server for model environment restoration.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1244\u001B[0m local_path \u001B[38;5;241m=\u001B[39m _download_artifact_from_uri(artifact_uri\u001B[38;5;241m=\u001B[39mmodel_uri)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/tracing/provider.py:422\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    420\u001B[0m disable()\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 422\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    424\u001B[0m     enable()\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1133\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001B[0m\n\u001B[1;32m   1131\u001B[0m         model_impl \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(conf[MAIN])\u001B[38;5;241m.\u001B[39m_load_pyfunc(data_path, model_config)\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1133\u001B[0m         model_impl \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mMAIN\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_pyfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1135\u001B[0m     \u001B[38;5;66;03m# This error message is particularly for the case when the error is caused by module\u001B[39;00m\n\u001B[1;32m   1136\u001B[0m     \u001B[38;5;66;03m# \"databricks.feature_store.mlflow_model\". But depending on the environment, the offending\u001B[39;00m\n\u001B[1;32m   1137\u001B[0m     \u001B[38;5;66;03m# module might be \"databricks\", \"databricks.feature_store\" or full package. So we will\u001B[39;00m\n\u001B[1;32m   1138\u001B[0m     \u001B[38;5;66;03m# raise the error with the following note if \"databricks\" presents in the error. All non-\u001B[39;00m\n\u001B[1;32m   1139\u001B[0m     \u001B[38;5;66;03m# databricks module errors will just be re-raised.\u001B[39;00m\n\u001B[1;32m   1140\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m conf[MAIN] \u001B[38;5;241m==\u001B[39m _DATABRICKS_FS_LOADER_MODULE \u001B[38;5;129;01mand\u001B[39;00m e\u001B[38;5;241m.\u001B[39mname\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/__init__.py:844\u001B[0m, in \u001B[0;36m_load_pyfunc\u001B[0;34m(path, model_config)\u001B[0m\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_pyfunc\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m, model_config: Optional[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# noqa: D417\u001B[39;00m\n\u001B[1;32m    839\u001B[0m     \u001B[38;5;124;03m\"\"\"Load PyFunc implementation for LangChain. Called by ``pyfunc.load_model``.\u001B[39;00m\n\u001B[1;32m    840\u001B[0m \n\u001B[1;32m    841\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    842\u001B[0m \u001B[38;5;124;03m        path: Local filesystem path to the MLflow Model with the ``langchain`` flavor.\u001B[39;00m\n\u001B[1;32m    843\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 844\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _LangChainModelWrapper(\u001B[43m_load_model_from_local_fs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m, path)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/__init__.py:883\u001B[0m, in \u001B[0;36m_load_model_from_local_fs\u001B[0;34m(local_model_path, model_config_overrides)\u001B[0m\n\u001B[1;32m    881\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m    882\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 883\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_model_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflavor_conf\u001B[49m\u001B[43m)\u001B[49m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/utils/__init__.py:584\u001B[0m, in \u001B[0;36mpatch_langchain_type_to_cls_dict.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    581\u001B[0m     module\u001B[38;5;241m.\u001B[39mget_type_to_cls_dict \u001B[38;5;241m=\u001B[39m _patched_get_type_to_cls_dict(originals[name])\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 584\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m m \u001B[38;5;241m:=\u001B[39m _CHAT_MODELS_ERROR_MSG\u001B[38;5;241m.\u001B[39msearch(\u001B[38;5;28mstr\u001B[39m(e)):\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/__init__.py:631\u001B[0m, in \u001B[0;36m_load_model\u001B[0;34m(local_model_path, flavor_conf)\u001B[0m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m register_pydantic_v1_serializer_cm():\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _RUNNABLE_LOAD_KEY:\n\u001B[0;32m--> 631\u001B[0m         model \u001B[38;5;241m=\u001B[39m \u001B[43m_load_runnables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_model_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflavor_conf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _BASE_LOAD_KEY:\n\u001B[1;32m    633\u001B[0m         model \u001B[38;5;241m=\u001B[39m _load_base_lcs(local_model_path, flavor_conf)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:505\u001B[0m, in \u001B[0;36m_load_runnables\u001B[0;34m(path, conf)\u001B[0m\n\u001B[1;32m    503\u001B[0m model_data \u001B[38;5;241m=\u001B[39m conf\u001B[38;5;241m.\u001B[39mget(_MODEL_DATA_KEY, _MODEL_DATA_YAML_FILE_NAME)\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lc_runnable_with_steps_types()):\n\u001B[0;32m--> 505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnable_with_steps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    507\u001B[0m     model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m picklable_runnable_types())\n\u001B[1;32m    508\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m model_data \u001B[38;5;241m==\u001B[39m _MODEL_DATA_PKL_FILE_NAME\n\u001B[1;32m    509\u001B[0m ):\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_from_pickle(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data))\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:140\u001B[0m, in \u001B[0;36m_load_runnable_with_steps\u001B[0;34m(file_path, model_type)\u001B[0m\n\u001B[1;32m    138\u001B[0m     config \u001B[38;5;241m=\u001B[39m steps_conf\u001B[38;5;241m.\u001B[39mget(step)\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;66;03m# load model from the folder of the step\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m     runnable \u001B[38;5;241m=\u001B[39m \u001B[43m_load_model_from_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     steps[step] \u001B[38;5;241m=\u001B[39m runnable\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;241m==\u001B[39m RunnableSequence\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:96\u001B[0m, in \u001B[0;36m_load_model_from_path\u001B[0;34m(path, model_config)\u001B[0m\n\u001B[1;32m     94\u001B[0m model_load_fn \u001B[38;5;241m=\u001B[39m model_config\u001B[38;5;241m.\u001B[39mget(_MODEL_LOAD_KEY)\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _RUNNABLE_LOAD_KEY:\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _BASE_LOAD_KEY:\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_base_lcs(path, model_config)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:505\u001B[0m, in \u001B[0;36m_load_runnables\u001B[0;34m(path, conf)\u001B[0m\n\u001B[1;32m    503\u001B[0m model_data \u001B[38;5;241m=\u001B[39m conf\u001B[38;5;241m.\u001B[39mget(_MODEL_DATA_KEY, _MODEL_DATA_YAML_FILE_NAME)\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lc_runnable_with_steps_types()):\n\u001B[0;32m--> 505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnable_with_steps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    507\u001B[0m     model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m picklable_runnable_types())\n\u001B[1;32m    508\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m model_data \u001B[38;5;241m==\u001B[39m _MODEL_DATA_PKL_FILE_NAME\n\u001B[1;32m    509\u001B[0m ):\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_from_pickle(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data))\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:140\u001B[0m, in \u001B[0;36m_load_runnable_with_steps\u001B[0;34m(file_path, model_type)\u001B[0m\n\u001B[1;32m    138\u001B[0m     config \u001B[38;5;241m=\u001B[39m steps_conf\u001B[38;5;241m.\u001B[39mget(step)\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;66;03m# load model from the folder of the step\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m     runnable \u001B[38;5;241m=\u001B[39m \u001B[43m_load_model_from_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     steps[step] \u001B[38;5;241m=\u001B[39m runnable\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;241m==\u001B[39m RunnableSequence\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:96\u001B[0m, in \u001B[0;36m_load_model_from_path\u001B[0;34m(path, model_config)\u001B[0m\n\u001B[1;32m     94\u001B[0m model_load_fn \u001B[38;5;241m=\u001B[39m model_config\u001B[38;5;241m.\u001B[39mget(_MODEL_LOAD_KEY)\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _RUNNABLE_LOAD_KEY:\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _BASE_LOAD_KEY:\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_base_lcs(path, model_config)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:505\u001B[0m, in \u001B[0;36m_load_runnables\u001B[0;34m(path, conf)\u001B[0m\n\u001B[1;32m    503\u001B[0m model_data \u001B[38;5;241m=\u001B[39m conf\u001B[38;5;241m.\u001B[39mget(_MODEL_DATA_KEY, _MODEL_DATA_YAML_FILE_NAME)\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lc_runnable_with_steps_types()):\n\u001B[0;32m--> 505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnable_with_steps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    507\u001B[0m     model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m picklable_runnable_types())\n\u001B[1;32m    508\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m model_data \u001B[38;5;241m==\u001B[39m _MODEL_DATA_PKL_FILE_NAME\n\u001B[1;32m    509\u001B[0m ):\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_from_pickle(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data))\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:140\u001B[0m, in \u001B[0;36m_load_runnable_with_steps\u001B[0;34m(file_path, model_type)\u001B[0m\n\u001B[1;32m    138\u001B[0m     config \u001B[38;5;241m=\u001B[39m steps_conf\u001B[38;5;241m.\u001B[39mget(step)\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;66;03m# load model from the folder of the step\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m     runnable \u001B[38;5;241m=\u001B[39m \u001B[43m_load_model_from_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     steps[step] \u001B[38;5;241m=\u001B[39m runnable\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;241m==\u001B[39m RunnableSequence\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:96\u001B[0m, in \u001B[0;36m_load_model_from_path\u001B[0;34m(path, model_config)\u001B[0m\n\u001B[1;32m     94\u001B[0m model_load_fn \u001B[38;5;241m=\u001B[39m model_config\u001B[38;5;241m.\u001B[39mget(_MODEL_LOAD_KEY)\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _RUNNABLE_LOAD_KEY:\n\u001B[0;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_runnables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_load_fn \u001B[38;5;241m==\u001B[39m _BASE_LOAD_KEY:\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_base_lcs(path, model_config)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/runnables.py:510\u001B[0m, in \u001B[0;36m_load_runnables\u001B[0;34m(path, conf)\u001B[0m\n\u001B[1;32m    505\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_runnable_with_steps(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data), model_type)\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    507\u001B[0m     model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m picklable_runnable_types())\n\u001B[1;32m    508\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m model_data \u001B[38;5;241m==\u001B[39m _MODEL_DATA_PKL_FILE_NAME\n\u001B[1;32m    509\u001B[0m ):\n\u001B[0;32m--> 510\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_from_pickle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_type \u001B[38;5;129;01min\u001B[39;00m (x\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lc_runnable_branch_types()):\n\u001B[1;32m    512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_runnable_branch(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, model_data))\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-9334fcee-142e-4161-95b7-0efa824da3d4/lib/python3.10/site-packages/mlflow/langchain/utils/__init__.py:421\u001B[0m, in \u001B[0;36m_load_from_pickle\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_from_pickle\u001B[39m(path):\n\u001B[1;32m    420\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m--> 421\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcloudpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n",
        "\u001B[0;31mTypeError\u001B[0m: code expected at most 16 arguments, got 18"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_uri = \"models:/genai_shared_catalog_03.ws_1286554779316081.rag_app/1\" \n",
    "with mlflow.start_run(run_name=\"lab_04_agent_evaluation\"):\n",
    "    eval_results = mlflow.evaluate(\n",
    "        data = DA.eval_df,\n",
    "        model = model_uri,\n",
    "        model_type = \"databricks-agent\",\n",
    "        extra_metrics=[is_readable]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14602661-3c65-46b9-bf13-f89ca9ee7447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "model.predict({\"inputs\": \"What is the capital of France?\"})  # Adjust input format as required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53fd5d2-0ac2-4241-8fd9-15486a5a9676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 3 - Review Evaluation Results\n",
    "\n",
    "Review the evaluation results in the **Experiments** section. Examine the following information regarding this evaluation:\n",
    "\n",
    "- Token usage\n",
    "\n",
    "- Model metrics\n",
    "\n",
    "- Results of the custom metric defined earlier (\"readability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1eb2e47-6cfb-4f0a-b190-6c7a52079ce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11. Evaluation with Mosaic AI Agent Evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}